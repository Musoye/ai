{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dc9mvBHAVww"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "\n",
        "image_path = './'\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "mnist_train_dataset = torchvision.datasets.MNIST(\n",
        "    root=image_path, train=True,\n",
        "    transform=transform, download=True\n",
        "    )\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(\n",
        "    root=image_path, train=False,\n",
        "    transform=transform, download=True\n",
        "    )\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "train_dl = DataLoader(mnist_train_dataset,\n",
        "                                          batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = [32, 16]\n",
        "image_size = mnist_train_dataset[0][0].shape\n",
        "input_size = image_size[0] * image_size[1] * image_size[2]\n",
        "all_layers = [nn.Flatten()]\n",
        "for hidden_unit in hidden_units:\n",
        "  layer = nn.Linear(input_size, hidden_unit)\n",
        "  all_layers.append(layer)\n",
        "  all_layers.append(nn.ReLU())\n",
        "  input_size = hidden_unit\n",
        "all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
        "model = nn.Sequential(*all_layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShXPIvgOBOSG",
        "outputId": "5260c1de-f370-4bf1-ab83-9d5df005ef76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "torch.manual_seed(1)\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "  accuracy_hist_train = 0\n",
        "  for x_batch, y_batch in train_dl:\n",
        "    pred = model(x_batch)\n",
        "    loss = loss_fn(pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    is_correct = (\n",
        "        torch.argmax(pred, dim=1) == y_batch\n",
        "        ).float()\n",
        "    accuracy_hist_train += is_correct.sum()\n",
        "  accuracy_hist_train /= len(train_dl.dataset)\n",
        "  print(f'Epoch {epoch} Accuracy '\n",
        "  f'{accuracy_hist_train:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae7VwyAuCGrj",
        "outputId": "414aedfd-8759-4cff-e23f-8e15df5367e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Accuracy 0.8531\n",
            "Epoch 1 Accuracy 0.9287\n",
            "Epoch 2 Accuracy 0.9413\n",
            "Epoch 3 Accuracy 0.9506\n",
            "Epoch 4 Accuracy 0.9558\n",
            "Epoch 5 Accuracy 0.9592\n",
            "Epoch 6 Accuracy 0.9627\n",
            "Epoch 7 Accuracy 0.9649\n",
            "Epoch 8 Accuracy 0.9673\n",
            "Epoch 9 Accuracy 0.9690\n",
            "Epoch 10 Accuracy 0.9711\n",
            "Epoch 11 Accuracy 0.9729\n",
            "Epoch 12 Accuracy 0.9737\n",
            "Epoch 13 Accuracy 0.9747\n",
            "Epoch 14 Accuracy 0.9766\n",
            "Epoch 15 Accuracy 0.9778\n",
            "Epoch 16 Accuracy 0.9780\n",
            "Epoch 17 Accuracy 0.9798\n",
            "Epoch 18 Accuracy 0.9806\n",
            "Epoch 19 Accuracy 0.9816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(mnist_test_dataset.data / 255.)\n",
        "is_correct = (\n",
        "    torch.argmax(pred, dim=1) ==\n",
        "    mnist_test_dataset.targets\n",
        "    ).float()\n",
        "print(f'Test accuracy: {is_correct.mean():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9AfRpZ6DMks",
        "outputId": "3a1e4859-0eee-4bb1-d86f-503b3ce31143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'mnist_classifier')"
      ],
      "metadata": {
        "id": "kIvbmVv5E9B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QezIaLIQWB3E",
        "outputId": "3d5dd23a-fed4-406f-cea9-90d9d847c62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST  mnist_classifier  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"mnist_classifier\")"
      ],
      "metadata": {
        "id": "ToZLQ5ONWdyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c2438367-f50b-4673-b138-288b418d3423"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d8dffec-b466-4939-a510-c9b6a80df7c8\", \"mnist_classifier\", 105954)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_83HWFNLYVMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}