{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "axkJAimjRbW4",
        "outputId": "b04cdd23-4b34-4c0f-b7bf-a7b4ae766825"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3477fdd9-a22b-45fe-8ddd-212904893255\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3477fdd9-a22b-45fe-8ddd-212904893255\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "upl = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pOqbWqnq7kK",
        "outputId": "4fc05b75-a685-4f2a-a0aa-ffe98a4d854c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SjzEEwoISBHT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upl = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "fDbKIX-oSYOS",
        "outputId": "c240f7a8-856b-4752-8d59-a5faf5641061"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-525084fc-e3f2-4ed7-9dbd-71c4e14a0727\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-525084fc-e3f2-4ed7-9dbd-71c4e14a0727\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip facial-expression-recognition-challenge.zip -d  facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLoBnAs3S9iQ",
        "outputId": "5149a1fa-aa58-4a16-b6de-5be2f0efcb5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  facial-expression-recognition-challenge.zip\n",
            "  inflating: facial-expression-recognition-challenge/example_submission.csv  \n",
            "  inflating: facial-expression-recognition-challenge/face_embs.npy  \n",
            "  inflating: facial-expression-recognition-challenge/fer2013.tar  \n",
            "  inflating: facial-expression-recognition-challenge/icml_face_data.csv/icml_face_data.csv  \n",
            "  inflating: facial-expression-recognition-challenge/metadata_processed.csv  \n",
            "  inflating: facial-expression-recognition-challenge/test.csv/test.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('facial-expression-recognition-challenge/metadata_processed.csv')\n",
        "emoticon = {'Angry': 0, 'Disgust' : 1, 'Fear' : 2, 'Happy' :3, 'Sad': 4, 'Surprise' : 5, 'Neutral': 6}\n",
        "df['emotion'] = df['emotion'].map(emoticon)\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "En5TvWtTTIcg",
        "outputId": "54db5c62-0afe-4750-8231-db9640d6bcdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                              image  emotion\n",
              "0      4  59 71 89 118 139 160 183 222 212 148 77 16 16 ...        4\n",
              "1      0  144 149 129 114 119 124 125 135 145 141 147 15...        0\n",
              "2      4  90 97 105 42 41 41 37 40 36 55 104 128 145 162...        4\n",
              "3      1  69 72 80 87 95 102 112 123 131 137 143 151 159...        1\n",
              "4      0  134 135 136 137 142 122 46 47 36 25 21 18 13 1...        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-249e36bd-7f37-411c-a9f3-639076925e13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>image</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>59 71 89 118 139 160 183 222 212 148 77 16 16 ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>144 149 129 114 119 124 125 135 145 141 147 15...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>90 97 105 42 41 41 37 40 36 55 104 128 145 162...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>69 72 80 87 95 102 112 123 131 137 143 151 159...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>134 135 136 137 142 122 46 47 36 25 21 18 13 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-249e36bd-7f37-411c-a9f3-639076925e13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-249e36bd-7f37-411c-a9f3-639076925e13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-249e36bd-7f37-411c-a9f3-639076925e13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-724f6dbc-0325-447b-846a-28ee539c293b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-724f6dbc-0325-447b-846a-28ee539c293b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-724f6dbc-0325-447b-846a-28ee539c293b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 35882,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          0,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25750,\n        \"samples\": [\n          \"35 35 35 36 36 38 38 40 41 40 41 47 33 1 0 0 0 0 0 1 0 1 1 2 3 3 2 6 19 17 8 5 4 5 4 5 1 3 3 1 4 18 85 102 97 97 92 93 30 33 34 33 34 35 33 36 35 37 37 41 14 0 1 0 0 0 0 0 1 2 3 3 3 2 6 19 39 47 40 30 14 2 3 7 7 5 5 2 1 0 22 99 106 101 97 98 23 25 25 25 26 25 26 27 27 26 29 21 1 0 0 0 0 0 1 1 2 5 4 4 7 9 13 38 66 64 56 52 46 22 4 0 4 7 4 6 1 3 0 40 109 108 103 103 11 10 11 11 10 11 11 11 11 11 13 5 0 0 0 0 0 1 0 1 1 2 6 11 13 17 34 65 74 73 73 66 66 56 32 9 1 2 1 5 4 2 7 0 57 115 106 109 12 13 15 16 18 22 23 24 26 29 26 1 0 0 0 0 0 1 2 3 2 5 14 20 20 31 57 76 77 77 83 84 77 76 67 47 17 4 1 2 8 14 9 2 17 107 120 110 32 33 35 36 37 39 41 42 42 49 20 0 1 1 1 1 0 0 2 4 4 4 15 23 36 53 64 77 84 85 89 89 81 91 82 74 58 34 14 3 8 18 14 7 9 72 119 117 35 37 39 39 40 40 45 46 49 45 3 0 0 1 1 1 2 5 6 4 13 20 24 32 48 55 64 77 91 95 95 97 94 89 88 83 81 79 64 21 7 6 14 11 19 43 64 90 37 40 42 42 44 45 47 49 54 25 0 2 1 0 2 5 5 9 18 23 24 34 35 37 43 53 68 80 96 103 102 99 95 92 91 91 81 85 81 63 24 6 15 22 35 49 49 48 35 36 37 38 40 42 41 43 43 5 0 0 0 2 2 4 8 16 21 27 33 42 37 32 45 60 76 89 102 106 109 107 100 96 88 92 85 83 81 77 58 28 26 31 40 51 54 51 41 43 46 47 49 51 50 55 38 0 0 17 11 0 3 7 10 18 22 35 37 33 38 42 59 73 79 89 106 115 111 113 114 110 94 95 94 90 88 82 73 50 45 29 36 48 51 49 33 37 39 41 42 42 45 49 25 2 52 81 75 23 0 12 18 24 26 37 45 49 52 59 71 79 87 98 110 115 119 120 120 129 112 108 96 93 95 89 78 54 46 20 16 31 41 44 38 41 45 43 46 49 51 62 20 33 99 90 83 78 16 12 27 36 34 42 44 47 52 54 52 72 86 99 111 122 123 130 129 129 120 113 103 98 94 92 81 59 48 38 26 30 27 33 51 53 53 51 58 60 64 65 16 73 95 84 106 97 77 37 34 40 41 49 51 54 62 75 80 88 101 105 114 129 134 137 134 133 127 118 105 104 92 87 80 65 50 51 52 57 51 50 59 61 48 64 77 72 72 68 19 88 80 100 123 97 106 80 49 43 43 48 51 62 83 103 115 115 120 123 130 137 139 137 128 123 124 120 110 108 95 89 84 66 52 56 65 66 62 73 68 61 55 80 85 89 80 72 30 79 101 115 106 101 102 87 63 55 51 51 57 86 103 108 114 112 113 121 128 127 131 134 128 121 115 115 107 111 95 92 86 70 53 58 71 70 65 75 73 57 67 84 85 91 87 66 26 81 95 106 112 93 91 76 63 72 77 71 81 106 111 110 115 115 110 109 115 117 125 129 133 126 121 120 107 105 92 94 77 67 53 62 74 73 69 77 73 57 76 83 86 92 87 72 21 84 81 100 119 87 87 69 63 72 84 91 101 112 115 115 112 114 109 113 122 121 118 128 141 135 123 115 107 102 92 94 79 67 50 66 74 73 70 79 74 61 84 83 88 92 87 80 18 83 102 94 103 102 99 67 60 76 87 98 111 115 117 116 104 113 109 114 124 130 130 137 137 128 125 112 100 103 86 92 92 69 49 68 75 74 71 79 72 67 91 86 89 94 89 87 17 62 112 114 111 111 92 68 67 80 96 106 108 115 118 117 124 127 112 107 106 101 108 100 92 101 117 114 106 100 92 98 103 65 52 68 75 75 72 79 71 74 94 91 94 96 97 86 25 20 86 119 122 108 82 68 72 85 98 105 107 113 113 117 130 124 102 87 107 110 92 79 58 70 102 107 103 90 104 117 106 60 54 68 76 77 74 80 73 80 94 95 94 95 99 95 41 21 59 96 114 97 76 73 75 89 101 103 103 106 107 124 129 120 102 79 63 93 98 85 60 37 42 57 56 89 103 108 100 63 57 71 77 77 75 82 74 80 95 95 93 95 101 97 68 16 54 80 117 107 71 72 84 90 98 101 100 106 114 125 129 123 105 98 77 38 29 31 57 73 69 77 109 98 75 63 54 46 60 76 77 77 75 83 76 85 94 91 86 95 107 101 87 23 46 70 100 95 70 79 84 85 94 100 100 110 116 119 133 135 119 102 95 78 48 34 81 134 119 122 108 40 43 44 18 23 69 79 79 79 77 86 76 89 91 88 79 93 109 99 98 35 46 66 77 80 70 80 83 85 89 89 98 113 117 118 133 145 138 114 91 76 67 75 98 114 112 122 71 52 53 50 36 51 74 79 79 81 78 86 73 88 90 84 75 89 108 100 96 40 52 72 64 71 73 82 84 86 89 94 97 109 117 121 126 143 135 116 102 97 95 112 117 104 111 100 67 36 17 37 58 63 73 77 78 79 77 84 71 87 90 73 69 85 108 105 70 35 48 59 58 70 78 87 87 88 85 93 99 107 118 120 120 142 141 119 106 102 104 116 124 114 112 88 58 47 34 48 57 61 76 78 79 78 77 86 71 87 91 64 88 87 105 108 46 31 45 53 55 71 77 89 90 87 87 95 96 107 117 118 123 137 134 115 107 97 94 117 135 118 111 79 61 55 60 60 55 61 77 79 79 80 78 87 72 94 78 79 108 88 105 102 33 42 60 61 53 72 75 85 94 91 99 90 95 111 116 117 123 126 122 110 94 83 91 110 113 104 114 82 70 70 63 54 60 70 78 80 79 81 78 85 73 92 74 96 112 86 104 72 25 49 59 49 52 67 74 84 95 93 95 89 99 114 113 119 125 120 108 87 85 102 101 92 88 91 103 78 74 69 58 59 76 79 76 77 78 79 77 85 79 92 80 103 110 92 90 38 34 44 43 51 60 67 68 76 86 86 92 96 97 108 111 116 121 107 85 97 126 130 96 87 101 129 110 76 70 66 58 69 78 78 77 77 78 77 75 79 84 92 84 103 107 105 54 34 41 49 52 63 77 64 64 69 73 80 90 100 103 100 105 114 105 89 106 119 125 125 108 81 74 103 106 78 64 59 60 77 78 78 77 77 77 77 76 84 82 90 83 104 115 86 39 41 47 64 49 67 87 68 71 68 69 76 86 94 101 91 99 107 99 103 107 104 108 102 100 94 82 59 53 52 63 51 65 78 78 78 78 79 77 78 76 87 80 95 90 93 78 54 49 41 40 60 52 80 89 76 74 69 71 66 81 86 87 91 106 104 97 88 92 103 104 98 94 86 71 51 44 72 51 53 71 79 79 80 80 80 78 79 75 85 77 68 31 20 37 57 41 39 59 56 78 92 92 82 76 76 73 64 74 84 80 86 97 86 86 87 94 78 69 80 90 82 69 42 77 71 44 59 77 79 83 81 78 81 79 80 76 84 134 60 0 46 67 65 48 44 57 67 87 89 92 82 79 80 74 63 66 76 77 83 85 80 99 117 122 115 86 54 53 61 44 50 83 48 48 65 80 79 80 80 80 82 79 80 76 84 150 69 19 76 80 70 48 44 70 96 95 83 90 93 81 75 74 68 67 67 64 65 75 77 79 93 102 110 110 85 61 40 31 78 57 44 53 77 80 80 80 79 80 81 77 79 75 83 80 14 21 86 80 72 51 66 88 96 98 87 86 97 89 75 74 68 73 74 69 56 62 77 77 84 98 92 71 56 53 45 66 60 44 49 68 83 79 80 80 79 79 81 78 78 73 81 7 1 6 67 83 73 60 81 95 99 99 92 87 95 95 79 73 66 71 84 87 76 55 68 81 83 86 86 75 49 33 36 50 44 46 61 81 81 80 80 82 79 79 80 78 78 73 82 3 5 0 24 80 66 72 88 99 102 102 94 93 92 96 95 75 63 58 70 80 88 68 43 60 60 61 61 51 46 24 40 48 47 60 76 79 80 81 82 81 78 77 80 78 77 74 83 2 3 4 0 39 84 77 91 101 104 108 100 94 95 96 101 94 71 55 50 64 73 83 67 44 35 39 43 53 33 1 11 38 64 83 80 79 81 79 80 80 77 77 80 77 76 72 79 2 2 2 3 1 44 90 99 105 109 108 108 99 96 96 97 98 90 73 50 35 52 72 82 78 67 43 27 18 1 3 3 4 16 36 59 75 84 88 83 80 77 79 80 75 75 72 80 1 2 2 3 2 0 41 104 116 111 108 109 112 103 96 93 95 94 89 77 57 38 30 33 39 34 18 2 0 3 3 4 4 1 0 2 11 24 45 73 87 78 78 79 75 75 72 80 1 1 2 2 3 3 0 20 82 120 118 108 108 106 99 91 86 85 86 91 91 85 74 58 43 30 9 3 5 3 3 3 3 4 4 3 2 0 0 9 44 76 84 80 73 74 71 78 1 2 2 2 0 2 7 0 0 37 89 117 119 108 98 91 83 83 86 87 89 88 80 72 66 37 5 4 4 3 3 3 3 3 3 4 4 4 4 3 0 15 49 73 77 72 72 77 1 2 2 1 7 25 5 3 3 0 0 30 73 101 95 92 94 103 108 102 96 84 74 67 40 5 3 4 3 3 3 3 3 3 3 3 3 3 3 4 5 2 0 10 49 74 69 75 0 0 0 21 67 31 0 3 2 4 3 0 0 10 35 80 111 115 111 110 98 74 46 20 3 3 4 4 2 2 2 3 3 3 3 3 3 3 2 3 4 5 5 1 1 52 75 73 6 16 15 12 26 5 1 2 2 2 2 4 4 1 0 2 14 14 12 14 13 7 0 1 4 4 3 3 2 2 2 3 3 2 2 2 2 2 2 3 4 3 3 4 2 7 59 76 32 38 33 39 3 0 2 2 2 2 2 2 3 3 4 3 0 0 1 0 0 2 4 4 3 3 3 2 3 2 2 3 3 2 2 2 2 2 3 3 3 3 3 3 4 0 18 70\",\n          \"109 123 121 127 127 129 130 134 133 133 138 137 133 129 129 126 128 120 119 119 111 110 104 98 103 104 113 123 134 146 154 141 150 152 179 197 171 162 192 203 192 194 250 254 251 255 211 171 110 128 126 126 127 130 129 134 135 137 134 134 135 129 131 129 124 122 132 123 121 117 117 106 90 89 100 111 122 141 154 158 162 167 187 198 189 181 197 207 204 207 248 255 253 255 216 213 116 127 133 127 129 132 134 135 137 140 135 131 138 139 136 135 133 135 136 127 128 129 134 135 114 94 90 101 111 128 148 169 183 194 174 194 195 193 193 204 206 221 248 255 254 255 236 185 123 124 134 129 132 136 136 138 135 135 136 133 134 137 135 130 123 116 98 94 90 95 98 114 121 124 120 114 117 130 149 170 179 161 157 185 206 182 183 207 215 226 248 255 255 255 254 238 126 128 131 133 130 132 133 138 137 132 130 130 130 121 110 95 99 111 112 92 79 93 97 83 80 90 115 123 128 131 139 145 137 137 155 179 212 167 186 205 217 210 236 255 254 255 246 204 130 134 129 135 129 132 132 133 135 129 123 121 116 105 102 93 113 164 125 62 61 76 170 140 90 79 101 119 127 135 134 131 132 140 151 198 215 204 214 205 197 198 235 255 254 255 255 245 132 134 133 132 129 132 131 130 131 126 117 114 114 114 114 116 106 132 120 76 55 76 174 139 99 94 102 113 126 140 138 136 133 134 167 221 206 191 196 188 189 215 247 255 253 255 217 157 135 136 134 131 131 130 130 127 126 121 113 114 119 121 121 123 127 116 87 75 63 77 141 120 94 99 108 115 128 140 140 135 132 137 195 170 110 115 138 181 215 245 255 255 251 254 218 176 135 136 134 133 131 132 132 131 124 117 112 112 116 123 125 126 128 129 123 98 83 110 130 99 95 89 110 119 129 136 137 133 127 134 194 141 115 129 152 183 241 255 254 255 252 254 190 159 135 135 135 136 134 134 132 130 127 122 119 116 113 118 127 132 131 126 126 125 123 120 118 104 95 96 110 115 123 130 133 128 123 126 176 154 107 134 205 194 226 254 253 255 253 254 215 160 132 136 135 136 136 134 134 131 128 126 126 123 119 117 120 126 132 133 127 125 124 121 118 106 101 103 103 109 119 127 130 128 123 119 153 167 72 115 228 247 250 253 254 255 254 255 232 159 133 134 135 137 136 139 140 137 131 130 130 127 125 123 120 123 129 133 132 132 130 128 119 108 102 99 102 112 118 123 124 124 124 123 138 189 82 127 238 254 253 254 254 255 252 251 192 160 133 134 136 139 138 141 142 140 136 133 133 133 133 128 130 128 127 129 131 132 130 124 118 112 102 103 114 120 124 123 120 118 123 128 136 185 153 169 238 253 253 254 254 255 252 242 133 176 133 136 139 140 140 141 142 140 140 138 137 139 139 134 134 133 131 129 126 126 125 121 116 110 106 114 118 120 124 123 124 121 124 127 128 173 211 201 227 254 254 254 254 255 255 247 157 160 130 134 138 136 139 140 142 140 142 141 140 141 140 139 139 132 128 128 126 124 124 116 111 110 113 118 119 123 123 124 123 121 122 123 128 155 213 217 248 254 254 254 254 255 253 254 242 239 147 164 167 161 139 140 141 141 143 143 143 143 143 143 143 136 156 162 157 152 118 110 114 114 116 118 118 121 122 120 122 120 121 116 150 149 206 237 253 254 255 255 255 255 253 249 206 145 168 143 142 148 137 136 136 136 141 141 139 140 140 142 139 158 162 130 129 134 109 132 135 108 117 115 114 117 121 121 118 117 117 114 150 141 198 245 247 253 255 255 255 255 254 243 176 178 151 131 139 135 137 157 164 162 141 143 158 153 167 156 134 160 160 124 121 115 121 153 151 134 112 133 152 152 131 119 134 148 147 123 147 137 177 233 233 248 255 254 255 255 253 255 228 186 151 132 138 138 139 146 138 155 162 147 177 152 149 173 143 138 162 163 153 133 117 148 142 118 130 160 137 148 157 126 160 132 133 120 145 137 170 235 240 254 254 255 255 255 254 255 226 155 152 134 137 139 136 145 150 157 166 147 167 133 134 166 147 132 130 138 148 165 130 142 139 108 138 142 112 117 147 130 143 108 113 110 145 158 191 219 245 255 254 255 255 255 253 254 218 168 154 128 135 132 153 164 139 153 163 145 165 134 137 167 145 133 130 124 116 153 148 144 141 103 128 133 97 105 135 120 141 104 114 112 148 134 156 225 239 255 254 255 255 255 252 254 196 172 166 156 154 149 153 166 143 163 167 145 167 134 136 170 139 148 164 148 148 166 131 141 157 120 108 141 118 132 134 105 146 133 138 122 149 137 146 207 238 250 255 255 255 255 254 247 199 160 136 153 158 142 132 153 152 143 149 139 149 131 135 150 137 131 148 154 150 135 122 126 139 123 93 111 135 133 114 105 120 140 139 117 135 132 143 187 224 246 254 254 254 255 254 249 172 219 131 128 130 125 134 135 133 130 132 135 133 135 138 136 138 136 130 127 125 127 131 126 99 80 102 113 119 127 134 130 125 123 125 124 121 125 138 179 233 254 253 254 254 255 253 252 253 229 130 134 134 135 135 136 137 136 136 136 138 139 139 138 137 137 133 133 134 133 133 121 93 92 116 125 136 134 120 124 134 135 132 134 131 127 141 184 232 254 254 254 254 255 253 255 205 160 130 129 131 132 130 135 134 134 134 135 138 137 139 138 137 134 134 133 134 137 131 106 94 98 121 129 110 65 59 82 96 115 129 132 136 141 173 193 234 255 254 254 254 255 254 255 215 148 130 127 125 125 130 131 134 132 132 134 138 138 138 138 135 134 132 134 135 138 117 100 99 92 112 123 88 69 89 118 115 101 112 128 135 182 221 232 253 255 255 255 255 255 253 255 220 130 125 133 127 122 128 131 134 132 133 134 137 134 135 137 136 136 130 134 138 128 109 103 104 100 95 110 110 109 114 121 136 160 165 173 192 237 252 254 255 255 255 255 255 255 255 243 225 255 125 130 126 125 126 130 132 131 128 129 135 134 136 137 138 136 132 133 131 116 114 115 111 108 101 102 110 113 116 135 166 199 220 207 217 241 254 253 255 255 255 255 255 255 254 243 178 196 125 124 117 127 124 128 130 129 132 130 133 135 134 135 138 137 137 129 119 113 118 118 115 113 111 109 109 111 118 161 178 179 224 203 215 248 254 254 255 255 255 255 255 255 253 254 235 198 122 116 125 124 123 127 126 128 133 131 129 133 134 134 137 134 135 129 111 119 122 119 116 116 115 114 110 112 127 181 164 172 224 214 228 254 253 254 255 255 255 255 255 255 253 244 176 172 114 124 127 117 124 125 119 126 125 128 133 131 130 135 134 132 127 123 121 117 121 119 118 118 117 112 111 107 136 192 165 169 220 222 240 255 254 254 254 255 255 255 255 254 255 219 116 205 124 131 122 117 120 120 120 121 122 127 130 130 131 131 132 129 123 118 125 124 115 115 117 116 114 108 109 115 147 196 153 162 215 231 250 255 254 254 255 255 255 255 255 255 254 249 147 106 130 121 118 117 118 115 121 121 124 125 125 127 131 132 129 124 121 121 119 127 119 113 116 113 111 105 104 121 166 192 136 161 215 242 255 255 255 255 255 255 255 255 255 255 254 254 255 249 118 122 124 122 118 119 122 121 124 126 127 125 130 130 127 121 119 118 116 117 125 116 107 110 108 106 115 133 185 183 140 169 218 252 254 255 254 255 255 255 255 255 255 255 255 253 252 255 122 122 124 123 117 120 124 120 124 124 128 128 129 126 120 117 117 116 117 115 110 118 109 112 117 119 126 139 187 180 145 181 230 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 118 121 120 117 116 121 121 119 120 122 125 127 125 123 116 114 113 114 116 109 114 117 128 119 122 126 129 142 170 173 168 204 243 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 113 116 119 117 116 115 117 119 121 121 123 125 123 117 114 118 111 110 115 121 124 125 127 141 133 135 136 138 144 165 191 212 251 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 113 112 118 117 118 115 117 117 117 121 125 126 121 113 112 113 111 114 117 121 129 140 135 120 109 107 117 129 142 178 184 224 255 253 255 255 255 255 255 255 255 255 255 255 255 255 255 255 110 115 119 116 116 118 117 113 117 118 123 125 116 112 110 108 113 114 119 131 134 98 61 50 45 57 48 56 104 143 187 249 254 254 255 255 255 255 255 255 255 255 255 255 255 255 255 255 108 109 116 116 117 118 116 118 114 116 119 119 112 109 111 109 110 126 136 105 66 41 47 51 48 57 63 64 104 151 235 255 253 254 255 255 255 255 255 255 255 255 255 255 255 255 255 255 109 107 106 113 118 116 115 115 115 117 120 116 108 107 108 106 122 129 85 65 62 47 44 48 48 50 59 89 108 207 255 252 254 254 255 255 255 255 255 255 255 255 255 255 255 255 255 255 104 107 105 109 116 112 113 113 117 117 118 114 106 101 102 108 135 73 63 64 53 42 49 47 49 55 65 88 154 247 255 253 254 254 255 255 255 255 255 255 255 255 255 255 255 255 255 255 103 106 105 109 114 110 109 113 115 112 106 105 104 102 104 105 135 63 46 48 43 44 46 51 54 59 66 86 214 249 247 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 101 103 104 106 108 106 108 111 111 107 104 104 106 105 106 102 119 116 36 33 58 47 45 51 53 58 57 123 247 253 242 250 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 98 97 104 106 107 107 108 109 109 102 101 103 104 103 105 103 98 124 121 47 48 53 47 51 53 62 74 160 255 253 253 243 251 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 93 95 99 100 103 105 104 106 102 102 101 101 102 101 102 102 102 103 119 128 82 48 49 47 48 64 101 195 255 251 255 253 243 251 255 255 255 255 255 255 255 255 255 255 255 255 255 255 92 93 96 93 100 103 102 101 101 103 98 98 101 100 101 102 103 106 98 120 135 102 82 71 56 69 109 208 255 252 255 255 251 242 253 255 255 255 255 255 255 255 255 255 255 255 255 255\",\n          \"0 3 0 57 135 137 152 159 156 159 163 166 162 162 158 158 158 153 155 146 150 156 149 131 127 131 138 139 143 140 130 135 132 121 109 100 84 77 69 66 65 58 39 21 7 19 30 12 0 2 0 36 131 138 147 157 154 156 160 163 159 158 155 158 156 149 150 139 145 156 147 128 131 138 145 145 143 140 130 118 118 110 90 82 73 63 66 60 55 49 33 14 3 13 23 8 0 1 0 22 127 138 148 156 156 157 159 162 160 156 160 153 154 144 147 148 145 145 137 132 140 151 149 139 125 125 118 98 93 84 83 79 65 63 63 44 30 30 23 14 4 12 17 6 0 1 0 11 119 142 147 159 161 155 157 159 158 155 159 150 147 141 139 148 138 132 136 139 140 141 130 117 111 104 90 89 83 78 74 67 66 67 55 41 32 29 25 21 10 17 15 6 0 1 1 1 108 147 148 158 164 161 161 159 154 149 153 150 147 137 134 141 125 125 134 132 117 97 90 89 85 74 66 63 67 69 66 72 77 73 64 49 36 42 22 27 23 8 14 9 0 1 1 0 100 152 149 153 159 165 161 150 140 136 142 143 146 143 118 123 119 116 113 93 72 58 49 45 49 52 56 57 66 74 74 63 55 46 42 28 21 28 31 31 29 14 24 16 0 0 2 0 86 137 138 144 149 159 147 130 120 124 134 132 139 143 126 101 100 107 97 73 51 27 29 77 95 93 93 106 108 108 102 93 82 69 45 16 7 9 28 38 30 26 46 32 0 0 1 0 56 113 104 111 118 115 109 89 80 92 114 120 131 144 134 121 92 73 72 57 29 12 68 113 104 98 87 90 86 90 78 66 61 54 53 42 15 1 6 27 43 55 62 61 3 6 2 0 39 101 85 74 81 84 79 65 64 69 87 97 110 139 137 129 108 75 42 30 18 13 85 100 87 53 61 78 70 59 49 10 6 4 8 15 25 22 16 31 59 80 80 70 1 2 4 0 26 83 74 77 70 85 92 89 83 94 104 99 103 130 138 135 112 80 48 24 13 1 60 88 58 58 75 57 88 73 41 2 2 0 0 5 15 23 41 55 63 68 103 89 0 0 1 0 4 70 94 102 99 107 117 109 102 95 100 99 86 101 128 125 109 82 54 24 11 2 18 56 60 70 52 91 125 94 17 11 0 5 21 20 11 16 39 40 63 94 120 94 0 0 0 1 0 74 116 112 98 110 98 76 59 73 89 93 74 75 135 145 143 120 76 29 15 11 3 45 78 77 72 91 103 117 88 42 40 43 33 15 33 18 35 44 102 131 108 83 0 0 0 1 0 54 109 78 108 86 30 13 39 12 34 57 71 88 147 161 152 135 89 37 33 32 10 41 70 83 92 96 97 92 87 80 66 47 45 61 48 32 51 69 116 118 92 84 0 0 0 2 0 49 111 94 55 63 68 20 38 0 20 34 55 83 146 159 154 137 85 41 67 58 35 32 80 96 94 87 86 80 75 75 84 78 76 79 58 62 76 111 112 108 88 74 0 0 0 2 0 54 132 66 36 81 99 42 25 60 82 81 72 95 154 152 152 140 80 48 75 65 70 56 71 102 106 97 96 100 103 107 111 100 99 86 76 102 126 117 106 99 88 70 0 0 0 2 0 51 141 69 80 96 93 100 108 118 96 100 108 120 156 154 153 125 83 58 74 86 69 93 103 109 114 106 108 112 111 114 109 95 82 81 108 140 129 106 92 84 78 62 0 0 0 2 0 36 145 90 93 124 119 119 114 97 101 115 112 127 152 154 150 113 86 79 72 94 69 101 114 110 116 122 105 95 100 97 90 91 108 134 146 130 106 93 83 78 66 58 0 0 0 1 0 14 134 136 108 118 125 117 102 110 126 119 116 139 150 157 146 104 72 72 63 80 66 85 106 107 110 134 128 119 116 116 129 146 154 150 132 113 95 81 70 70 62 48 0 0 0 0 0 1 107 156 125 122 128 132 133 130 116 114 137 147 150 154 134 92 65 60 64 88 68 74 91 106 109 136 147 144 155 158 158 160 148 138 121 104 87 76 66 59 57 43 0 0 0 0 1 0 89 152 131 125 141 146 128 105 114 135 155 144 151 156 123 81 68 65 73 78 70 58 79 102 117 139 149 145 151 153 155 154 145 129 114 99 82 72 68 60 47 37 0 0 0 0 3 0 79 154 144 133 126 117 112 120 140 157 156 139 153 151 107 79 77 78 75 63 47 43 73 108 121 143 149 147 145 150 156 152 145 126 110 96 84 67 59 54 45 33 0 0 0 0 2 0 75 153 144 146 140 135 145 153 155 164 158 142 151 148 112 96 89 80 69 44 24 21 57 106 127 145 148 145 148 148 149 147 135 119 106 93 81 58 54 46 37 32 0 0 0 0 2 0 52 145 143 149 153 152 155 158 163 164 159 141 150 149 111 95 85 72 48 21 9 2 13 64 130 151 147 144 150 150 154 149 131 109 98 88 73 56 47 41 29 27 0 0 0 0 2 0 33 134 138 148 151 160 161 160 162 164 152 138 153 144 115 103 80 57 35 22 9 20 26 8 69 135 148 147 149 148 162 150 128 107 98 81 63 51 35 26 28 26 0 0 0 0 0 0 5 112 138 136 147 160 163 163 161 158 142 140 157 142 121 103 75 59 41 38 54 74 75 44 8 54 122 139 141 148 143 139 121 108 90 76 58 50 33 21 23 26 0 0 0 0 0 2 0 72 136 138 151 157 162 163 160 157 137 137 152 145 120 99 79 65 47 59 66 72 67 62 31 0 46 114 133 142 140 130 118 106 92 71 55 50 29 24 21 19 0 0 0 0 0 2 0 20 119 140 149 157 157 158 156 153 136 137 142 136 121 105 87 61 46 55 37 30 29 29 23 9 7 60 112 125 129 120 111 100 90 72 61 45 33 26 20 16 0 0 0 0 0 0 0 1 87 130 142 153 151 158 156 147 131 135 149 144 120 104 75 49 32 23 13 6 8 14 16 8 39 64 90 110 116 110 106 94 83 74 62 48 37 24 18 18 0 0 0 0 0 0 1 0 48 127 137 148 156 158 152 139 114 128 142 144 113 74 43 28 16 2 0 0 0 3 4 16 65 100 101 100 104 100 98 92 78 70 65 57 41 34 24 14 0 0 0 0 0 0 1 0 12 109 135 146 152 155 143 127 94 93 117 117 97 57 36 20 4 2 2 0 0 2 20 39 73 108 117 101 95 99 94 88 80 73 66 56 42 36 27 15 0 0 0 0 0 0 0 1 0 76 133 140 149 146 127 110 79 78 111 93 89 62 24 7 7 3 0 1 15 39 57 57 74 96 113 106 98 92 92 89 78 76 68 60 51 39 27 19 0 0 0 0 0 0 0 2 0 38 125 138 142 136 122 99 69 108 147 109 83 70 51 42 31 28 41 50 56 58 63 65 75 92 106 99 105 95 81 86 82 76 70 65 56 46 36 25 0 0 0 0 0 0 0 0 0 7 104 135 138 130 115 90 79 130 151 132 104 110 115 104 95 84 90 78 62 66 63 73 79 91 96 92 103 90 89 74 69 77 73 67 67 55 44 45 0 0 0 0 0 0 0 0 2 0 75 133 130 127 113 82 100 144 148 133 117 113 113 106 108 100 90 76 60 70 70 73 87 87 92 87 97 90 92 86 64 56 66 76 75 69 64 56 0 0 0 0 0 0 0 0 2 0 47 128 126 122 105 86 116 149 147 138 125 115 107 94 95 99 96 77 69 70 79 77 85 85 76 77 82 87 87 76 68 61 59 81 87 72 60 64 0 0 0 0 0 0 0 0 1 0 23 118 123 116 99 94 131 145 143 141 131 119 112 94 98 103 107 87 74 84 80 64 77 74 66 64 74 74 65 56 59 70 76 88 101 74 48 55 0 0 0 0 0 0 0 0 0 0 5 99 118 110 94 99 134 142 142 142 136 128 125 101 100 112 107 101 82 95 59 57 70 62 59 50 54 43 38 39 53 69 92 115 109 98 87 71 0 0 0 0 0 0 0 0 0 1 0 75 118 104 98 107 131 136 133 128 133 136 135 118 107 112 96 77 61 51 36 36 34 31 23 16 11 10 13 24 45 66 105 124 116 102 90 74 0 0 0 0 0 0 0 0 0 2 0 46 124 112 102 109 120 126 127 124 138 135 129 110 96 85 29 15 12 6 3 3 5 5 4 6 21 24 21 27 41 67 107 124 113 95 72 59 0 0 0 0 0 0 0 0 0 0 0 15 110 122 117 114 113 119 126 141 149 139 133 107 83 102 61 7 0 4 23 20 15 25 41 44 44 33 32 49 52 58 83 117 110 90 65 52 0 0 0 0 0 0 0 0 0 1 2 0 89 142 144 132 128 135 136 151 147 135 137 110 77 103 110 64 10 20 35 23 22 39 48 35 19 27 56 64 49 44 61 87 96 83 63 48 0 0 0 0 0 0 0 0 1 4 0 72 157 153 152 147 135 148 145 150 153 141 119 91 76 105 99 76 34 32 30 30 34 30 19 8 13 48 64 50 41 43 61 75 73 70 54 41 0 0 0 0 0 1 2 2 2 0 32 160 155 152 156 147 128 130 141 143 161 155 138 99 73 98 93 64 24 28 33 30 23 15 5 8 36 49 45 41 43 69 75 64 53 57 46 32 0 1 1 0 2 0 0 0 1 53 143 163 158 154 157 146 128 115 130 135 149 150 139 106 76 93 82 51 19 21 19 14 10 7 8 24 36 32 36 47 68 81 74 58 38 30 38 33 0 1 1 2 0 15 77 99 125 160 158 155 160 154 154 149 135 121 117 129 148 146 125 99 86 90 64 36 18 23 12 5 6 6 16 28 25 28 46 68 72 65 54 40 30 19 10 17 0 0 2 0 26 147 174 155 147 150 154 154 156 153 146 152 135 134 126 129 147 152 127 94 82 78 52 34 15 23 22 3 6 8 15 18 26 46 63 64 58 49 34 17 8 9 8 3 0 1 1 19 147 174 161 154 146 139 149 150 145 143 150 151 137 126 125 130 143 152 129 93 71 67 46 32 17 31 60 16 2 8 11 29 48 60 63 52 42 32 19 44 73 77 65 45 0 3 0 93 180 160 163 167 158 142 135 150 148 140 143 150 149 132 121 127 144 150 134 99 68 57 40 21 15 46 75 46 11 13 29 52 61 66 61 40 34 23 72 115 104 96 77 45\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          0,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def process_image(image_string):\n",
        "    # Split the string into a list of integers\n",
        "    pixel_values = np.fromstring(image_string, dtype=int, sep=' ')\n",
        "\n",
        "    # Reshape into a 48x48 array (assuming the images are 48x48)\n",
        "    image_array = pixel_values.reshape(48, 48)\n",
        "\n",
        "    # Convert to a PyTorch tensor\n",
        "    tensor_image = torch.tensor(image_array, dtype=torch.float32)\n",
        "\n",
        "    # Normalize the pixel values to the range [0, 1] if needed\n",
        "    tensor_image /= 255.0\n",
        "\n",
        "    return tensor_image\n",
        "\n",
        "df['image'] = df['image'].apply(process_image)"
      ],
      "metadata": {
        "id": "EZD1BVobTOGw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "df['image'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J98CL5Q1Tcyn",
        "outputId": "a95f9ba2-80cb-4fa1-8155-565e3c221f96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35882,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((28, 28)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.5], [0.5])\n",
        "# ])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "image_tensors = torch.stack(df['image'].tolist())\n",
        "image_tensors = image_tensors.view(-1, 1, 48, 48)\n",
        "label_tensors = torch.tensor(df['emotion'].tolist(), dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(image_tensors, label_tensors)\n"
      ],
      "metadata": {
        "id": "1B6UUYnnWHZv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataset = TransformDataset(train_dataset, transform)\n",
        "valid_dataset = TransformDataset(test_dataset, transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwsGQMNwYStb",
        "outputId": "9e139527-45ce-48a4-b129-042440b7ad71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 28705\n",
            "Number of testing samples: 7177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89k7Pr8yb4Eo",
        "outputId": "346c49da-f171-4808-fa85-fa0d7aa8ba92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "facial-expression-recognition-challenge      kaggle.json\n",
            "facial-expression-recognition-challenge.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "lr = 0.001\n",
        "n_ch =1\n",
        "\n",
        "model = nn.Sequential()\n",
        "\n",
        "#featurizer\n",
        "model.add_module('c1', nn.Conv2d(\n",
        "    in_channels=1, out_channels=n_ch, kernel_size=3\n",
        "))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('maxp1', nn.MaxPool2d(kernel_size=2))\n",
        "model.add_module('flatten', nn.Flatten())\n",
        "\n",
        "#classfication\n",
        "model.add_module('fc1', nn.Linear(n_ch*13*13, 70))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('fc3', nn.Linear(70, 35))\n",
        "model.add_module('relu3', nn.ReLU())\n",
        "model.add_module('fc4', nn.Linear(35, 12))\n",
        "model.add_module('relu4', nn.ReLU())\n",
        "model.add_module('fc2', nn.Linear(12, 7))\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7WfqT3yvjSH",
        "outputId": "ffe8da8a-fa6e-4842-e1cf-9a52f6cc0d2b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (c1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (maxp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=169, out_features=70, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (fc3): Linear(in_features=70, out_features=35, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (fc4): Linear(in_features=35, out_features=12, bias=True)\n",
              "  (relu4): ReLU()\n",
              "  (fc2): Linear(in_features=12, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "torch.manual_seed(1)\n",
        "num_epochs = 50\n",
        "log_epoch = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  accuracy_hist_train = 0\n",
        "  for images, labels in train_loader:\n",
        "    pred = model(images)\n",
        "    loss = loss_fn(pred, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    is_correct = (\n",
        "        torch.argmax(pred, dim=1) == labels\n",
        "        ).float()\n",
        "    accuracy_hist_train += is_correct.sum()\n",
        "  accuracy_hist_train /= len(train_loader.dataset)\n",
        "  if (epoch % log_epoch == 0):\n",
        "    print(f'Epoch {epoch + 1} Accuracy '\n",
        "    f'{accuracy_hist_train:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVnhPPFvb6Ff",
        "outputId": "6f1caad4-0b9b-4058-bc56-e386f30927f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Accuracy 0.2477\n",
            "Epoch 6 Accuracy 0.4270\n",
            "Epoch 11 Accuracy 0.4870\n",
            "Epoch 16 Accuracy 0.5189\n",
            "Epoch 21 Accuracy 0.5422\n",
            "Epoch 26 Accuracy 0.5635\n",
            "Epoch 31 Accuracy 0.5837\n",
            "Epoch 36 Accuracy 0.5987\n",
            "Epoch 41 Accuracy 0.6098\n",
            "Epoch 46 Accuracy 0.6277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "ans = files.upload()"
      ],
      "metadata": {
        "id": "TU8TcpkjeNWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ff53fdbb-7ede-443e-af85-584bd520e72a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-adacb5fb-59ae-42e2-a6bf-cf4657238bc2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-adacb5fb-59ae-42e2-a6bf-cf4657238bc2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sad.jpeg to sad.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import  Image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "image = Image.open('sad.jpeg')\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "output = model(image_tensor)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRBpHjNpIcq5",
        "outputId": "eccc2284-9dd6-41d6-d691-b56f6f903437"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2.1164, -25.9275,  -0.7778,   2.3993,   2.6792,  -4.5614,   2.4400]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'facial_emotion.ph')"
      ],
      "metadata": {
        "id": "tJwLP-HBI7Ie"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkfUcj3rJhmP",
        "outputId": "d22bc281-2fca-4d5a-d105-7d49ea893764"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('c1.weight',\n",
              "              tensor([[[[ 0.2856, -1.6876,  0.5857],\n",
              "                        [-0.8934, -0.7841, -0.0956],\n",
              "                        [ 0.9468,  0.9653, -0.4577]]]])),\n",
              "             ('c1.bias', tensor([0.2809])),\n",
              "             ('fc1.weight',\n",
              "              tensor([[-0.1515,  0.1750,  0.0928,  ..., -0.0988,  0.2175,  0.2046],\n",
              "                      [ 0.2790,  0.0098,  0.0942,  ...,  0.2133,  0.0073, -0.0461],\n",
              "                      [ 0.3790,  0.0252, -0.1205,  ..., -0.1836,  0.2561, -0.1155],\n",
              "                      ...,\n",
              "                      [ 0.2517,  0.2924,  0.2205,  ..., -0.0788, -0.2180, -0.0305],\n",
              "                      [-0.2272, -0.2113, -0.0793,  ..., -0.2275,  0.0845, -0.5135],\n",
              "                      [-0.0169, -0.0587,  0.0427,  ..., -0.0930, -0.0861, -0.3494]])),\n",
              "             ('fc1.bias',\n",
              "              tensor([ 0.2998, -0.0417, -0.2051, -0.5162, -0.2020, -0.2206, -0.0862,  0.0325,\n",
              "                       0.1138,  0.0866, -0.1578, -0.4352,  0.0909, -0.0329,  0.2853,  0.0145,\n",
              "                       0.3294, -0.0705,  0.1058,  0.0438, -0.3049, -0.0660, -0.2604, -0.5984,\n",
              "                      -0.2910,  0.1178, -0.1131, -0.0261,  0.0055, -0.0278,  0.1389,  0.2696,\n",
              "                       0.1790, -0.0733, -0.7020, -0.3105,  0.3135,  0.2223, -0.1219, -0.0880,\n",
              "                       0.3298,  0.1263,  0.0924, -0.0316, -0.2988, -0.3665, -0.0131,  0.3176,\n",
              "                      -0.2141,  0.4036,  0.0122,  0.1721,  0.2982,  0.0751, -0.2877,  0.3144,\n",
              "                      -0.0963, -0.1845, -0.0270, -0.1551,  0.1976,  0.3450,  0.0039, -0.3908,\n",
              "                       0.0874,  0.0814, -0.2348,  0.3951,  0.4549, -0.0139])),\n",
              "             ('fc3.weight',\n",
              "              tensor([[ 0.2867,  0.1705,  0.0047,  ..., -0.6082, -0.2394,  0.3278],\n",
              "                      [ 0.0823,  0.1524, -0.1576,  ..., -0.2982,  0.1413,  0.3375],\n",
              "                      [-0.9074,  0.3347, -0.1968,  ...,  0.5001, -0.4048, -0.8565],\n",
              "                      ...,\n",
              "                      [ 0.0143,  0.2757, -0.1592,  ...,  0.3348, -0.7101, -0.2799],\n",
              "                      [ 0.4105, -0.1727,  0.1549,  ..., -0.3259, -0.5697,  0.3839],\n",
              "                      [ 0.4630,  0.1631,  0.2219,  ..., -0.3606, -0.2745,  0.5271]])),\n",
              "             ('fc3.bias',\n",
              "              tensor([ 0.2450, -0.0780,  0.4944,  0.0215, -0.0393,  0.2010,  0.3320,  0.0091,\n",
              "                       0.3931, -0.1769,  0.3603,  0.2023,  0.2491,  0.1596,  0.2685,  0.1558,\n",
              "                       0.0201,  0.1678, -0.2416,  0.2568, -0.1926, -0.1859, -0.1078,  0.3834,\n",
              "                       0.3565,  0.0290, -0.1548,  0.0764, -0.0432,  0.3312,  0.1239, -0.0180,\n",
              "                       0.4489, -0.3912,  0.2060])),\n",
              "             ('fc4.weight',\n",
              "              tensor([[ 0.2108, -0.5274,  0.3170,  0.5688,  0.4755, -0.0955,  0.2994,  0.2391,\n",
              "                        0.2307, -0.2519, -0.2014, -0.0381, -1.2559, -0.9149, -0.0962,  0.3761,\n",
              "                        0.4251,  0.1596, -0.5470, -0.2573, -0.0843,  0.0669, -0.2050,  0.1581,\n",
              "                       -0.4618,  0.1032,  0.0244,  0.2538, -0.2104,  0.3814, -0.0354,  0.0224,\n",
              "                       -0.0977,  0.6001,  0.3420],\n",
              "                      [-0.1361,  0.8850,  0.1332, -0.7214, -0.4796, -0.6559,  0.6856, -0.3244,\n",
              "                       -0.0930,  0.0470, -0.7860,  0.0982, -0.3227,  0.0506,  1.2349, -0.6861,\n",
              "                       -0.2448,  0.4178,  0.0394,  0.1456, -0.0053,  0.0713, -0.5450,  0.3403,\n",
              "                        0.6202,  0.0472, -0.0312, -1.0341,  0.9262,  0.0716, -0.1790,  0.6459,\n",
              "                       -0.0235, -0.3383,  0.2461],\n",
              "                      [ 0.7490,  0.1613,  0.3212,  0.4539,  0.0561,  1.1554, -0.0945,  0.2381,\n",
              "                        0.4177,  0.0087,  1.1249, -0.1527,  1.1992,  0.5320, -0.6597,  0.4615,\n",
              "                        0.5799, -0.4515,  0.5392,  0.1990,  0.1349,  0.0637,  0.6139, -0.0511,\n",
              "                       -0.1760, -0.0764, -0.1092,  0.7272, -0.8897, -0.2317,  0.3926, -0.7838,\n",
              "                        0.3656,  1.1667, -0.2263],\n",
              "                      [ 0.1739,  1.0795, -0.0920,  0.2247,  0.4185,  0.2841,  0.3907, -0.3168,\n",
              "                       -0.6642,  0.1695,  0.2705, -0.7837,  0.3331,  0.6757, -0.2005,  0.1054,\n",
              "                        0.1245, -0.6898, -0.2411,  0.1435,  0.0709, -0.0371,  0.3222, -0.2801,\n",
              "                       -0.1111, -0.4920,  0.1245,  0.8584, -0.4578, -0.0380, -0.5438,  0.3423,\n",
              "                        0.3464, -0.5584, -1.0249],\n",
              "                      [ 0.0161,  0.1373,  0.4553,  0.0922, -0.4098,  0.0091,  0.0880,  0.1934,\n",
              "                       -0.2954,  0.3378,  0.0021,  0.0083,  0.2706,  0.2673, -0.4517,  0.3183,\n",
              "                        0.4958, -0.0689, -0.4188,  0.4599,  0.1311,  0.1680,  0.2326, -0.1178,\n",
              "                        0.6870,  0.8678, -0.0250, -0.0078, -0.0454, -0.3216,  0.0618, -0.0258,\n",
              "                        0.6789, -0.7261, -0.0814],\n",
              "                      [-0.3317,  0.1172, -0.4533, -0.4756,  0.3682,  0.0538,  0.4130, -0.0877,\n",
              "                        0.3132, -0.4022, -0.0078, -0.0912, -0.6743,  0.3395, -0.1377, -0.1223,\n",
              "                       -0.4621,  0.2504, -0.0396, -0.1755,  0.1517, -0.1594,  0.2690,  0.5018,\n",
              "                       -0.2787, -0.2764, -0.1595,  0.1900, -1.4172,  0.0138, -0.0045, -0.9183,\n",
              "                        0.3988, -0.5116,  0.1234],\n",
              "                      [ 0.3043,  0.3920, -0.3378, -0.0667, -0.0401, -0.1325,  0.1826, -0.4235,\n",
              "                        0.0539,  0.1666, -0.4000, -0.1665,  0.3447,  0.1153,  0.8241, -0.1981,\n",
              "                       -0.1559,  0.8058, -0.1098,  0.3629,  0.0585, -0.0437,  0.0661,  0.4079,\n",
              "                        0.0736, -1.3290,  0.0350,  0.3275,  0.7608,  0.0278, -0.2239,  0.4702,\n",
              "                       -0.0421, -0.5281,  0.1355],\n",
              "                      [-0.1380, -1.0363,  0.6549, -0.4994, -0.4059,  0.2773, -0.2074,  0.0427,\n",
              "                        0.1637, -0.1860, -0.1031,  0.1591, -0.3593, -0.0945,  0.1632,  0.0551,\n",
              "                        0.3700, -0.0559, -0.0588,  0.2377,  0.1204,  0.0710, -0.4428,  0.6162,\n",
              "                       -0.1307, -0.9533,  0.0031, -0.2632,  0.4441,  0.3112,  0.3229, -0.1163,\n",
              "                        0.3347,  0.3827, -0.0978],\n",
              "                      [-0.0725,  0.3653,  0.3848,  0.3578, -0.0500,  0.3165,  0.0843, -0.2775,\n",
              "                       -0.2376, -0.5665,  0.7432, -0.3231,  0.3697,  0.6670, -0.2761,  0.3346,\n",
              "                       -0.1022, -1.2022,  0.3384,  0.0709, -0.0404, -0.0173,  0.3190, -0.3005,\n",
              "                        0.2752,  0.5386, -0.0066,  0.7230, -0.4240,  0.5279, -0.0695, -0.3972,\n",
              "                        0.2224, -0.4613, -0.5301],\n",
              "                      [ 0.3461,  0.3547, -0.1317, -0.3373, -0.3334, -0.0726, -0.5889,  0.2919,\n",
              "                       -0.2318,  0.0604,  0.4125, -0.3317, -0.2900,  0.7008, -0.6517, -0.4692,\n",
              "                       -0.6128, -0.3348, -0.1628, -0.0122, -0.1350,  0.1630,  0.4008, -0.1145,\n",
              "                       -0.5016, -0.0227, -0.1005, -1.4587,  0.0113, -0.7050, -0.0908, -0.2654,\n",
              "                        0.2148,  0.1532, -1.0666],\n",
              "                      [ 0.1959, -0.2722, -0.9979,  0.2473,  0.7724, -0.1337,  0.5114, -0.0478,\n",
              "                        0.1320,  0.2906, -0.1917,  0.3150, -0.7913, -0.7007,  0.7802,  0.1036,\n",
              "                        0.0059,  1.1204,  0.2280,  0.0515, -0.0897,  0.1442, -0.1774,  0.3328,\n",
              "                       -0.2953,  0.2649,  0.0778, -0.1982,  1.1085,  0.0531,  0.1955, -0.5587,\n",
              "                       -0.4457,  0.3646,  0.1524],\n",
              "                      [-0.3697,  0.3215,  0.5187,  0.2017,  0.7497, -0.2971,  0.1767, -0.4133,\n",
              "                       -0.2424,  0.1034, -0.2021,  0.0745,  0.3620,  0.6560,  0.6431, -0.0291,\n",
              "                       -0.3114,  0.4781, -0.1507, -0.2495,  0.1161,  0.1055, -0.1875,  0.4376,\n",
              "                        0.2202, -0.6291,  0.1056,  0.4177,  0.6448,  0.9087,  0.1319,  0.4011,\n",
              "                       -0.1810, -0.4767,  0.2397]])),\n",
              "             ('fc4.bias',\n",
              "              tensor([0.2616, 0.3700, 0.2122, 0.0341, 0.0211, 0.1545, 0.0119, 0.1726, 0.3588,\n",
              "                      0.3689, 0.3577, 0.2917])),\n",
              "             ('fc2.weight',\n",
              "              tensor([[-0.2450, -0.2310,  0.4187,  0.1180, -0.3266, -0.3977,  0.3921,  0.1783,\n",
              "                       -0.3300, -1.6428,  0.0289, -0.8477],\n",
              "                      [-0.4949,  1.3262, -2.1138, -1.1313, -0.6727, -0.8981,  0.5561, -0.3852,\n",
              "                       -1.6329, -0.7784,  0.2797,  1.1955],\n",
              "                      [-0.6477, -0.0478,  0.2294, -1.0750,  0.2850,  0.9486, -0.5982, -0.4947,\n",
              "                        0.5526,  0.2628, -0.1355, -0.2876],\n",
              "                      [ 0.5031, -0.6194,  0.1664,  0.1833, -0.4764,  0.0941, -0.5386, -0.2271,\n",
              "                        0.1890, -0.7959,  0.2229,  0.3415],\n",
              "                      [ 0.1336, -0.5329,  0.0473, -0.7155,  0.3459, -0.3748, -0.1191, -0.0622,\n",
              "                       -0.2347, -0.9877,  0.0612, -0.0539],\n",
              "                      [-0.1468, -0.4589,  0.2959,  1.0441, -0.0626, -0.2222,  0.5414, -0.3883,\n",
              "                        0.4814,  1.1613, -0.9706,  0.1679],\n",
              "                      [ 0.3142, -0.0556,  0.0531, -0.2527,  0.1928, -0.0695, -0.3726,  0.5027,\n",
              "                       -0.2538, -0.0280, -0.2495, -0.1045]])),\n",
              "             ('fc2.bias',\n",
              "              tensor([-0.2370, -0.1497,  0.3686,  0.1412, -0.0887, -0.1845, -0.1848]))])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('facial_emotion.ph')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_5XkqwdQJm5q",
        "outputId": "5ed56a7e-c07f-4907-d423-0e52711e4d08"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e1cff3d-8a1a-4135-9393-b2086a4e17bb\", \"facial_emotion.ph\", 63322)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iALYplHxJ0aj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}